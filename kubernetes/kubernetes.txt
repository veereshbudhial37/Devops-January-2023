Kubernetes - k8s 
The architecture of k8s differs from master and worker node 

	Master node components 
		1. Api Server / kube-api-server
			- It is the main management point of the cluster and also called 
			  as brain of the cluster.
			- All the components are directly connected to API serve, they 
			  communicate through API server only and no other component will 
			  communicate directly with each other.
			- This is the only component which connects and got access to etcd.
			- All the cluster requests are authenticated and authorised by API server.
			- API server has a watch mechanism for watching the changes in cluster.
			
		2. etcd 
			- ectd is a distributed , consistent key value store used for 
			  storing the complete cluster information/data.
			- ectd contains data such as configuration management of cluster,
              distributed work and basically complete cluster information.			
			
		3. scheduler / kube-scheduler
			- The scheduler always watches for a new pod request and 
			  decides which worker node this pod should be created.
			- Based on the worker node load, affinity and anti-affiny, taint configuration 
			  pod will be scheduled to a particular node.
			  
		Controller manager /control manager / kube-controller 
			- It is a daemon that always runs and embeds core control loops known as controllers. 
			- K8s has some inbuild controllers such as Deployment, DaemonSet, ReplicaSet, Replication controller,
			  node controller, jobs, cronjob, endpoint controller, namespace controller etc.	
			
		Cloud controller manager 
			- These controller help us to connect with the public cloud provider service and this component 
			  is maintained by cloud providers only.

Worker node components 
		kubelet 
			- It is an agent that runs on each and every worker node and it alsways watches the API 
			  server for pod related changes running in its worker node.
			- kubelet always make sure that the assigend pods to its worker node is running.
			- kubelet is the one which communicates with containarisation tool (docker daemon)
              		  through docker API (CRI). 	
			- work of kubelet is to create and run the pods. Always reports the status of the worker node 
			  and each pod to API server. (uses a tool call cAdvisor)
			- Kubelet is the one which runs probes.	
		
		kube service proxy 
			(in k8s service means networking)
			- Service proxy runs on each and every worker node and is responsble for watching API 
			  server for any changes in service configuration (any network related configuration).	
			- Based on the configuration service proxy manages the entire network of worker node.

		Container runtime interface (CRI)
			- This component initialy identifies the container technology and connects it to kubelet.
			
		pod
			- pods are the smallest deployable object in kuberntes.
			- pod should contain atleast one container and can have n number of containers.
			- If pod contains more than one container all the container share the same memory assigned to that pod.


Assignment: What happens when a new pod request comes to control plane / Master node ? 
			https://medium.com/jorgeacetozi/kubernetes-master-components-etcd-api-server-controller-manager-and-scheduler-3a0179fc8186

Linux namespaces and cgroups 
	namespaces 


YAML syntax 
 - filetype .yaml or .yml
 - YAML consists of key - value pairs 
 - Key is always defined by the tool - k8s 
 - Values will be defined by user.
 		Types of values we can provide 
 			- Integer (Numeric)
 			- Sting (Alphanumeric)
 			- Array 
 			- List 
 			- Boolean 

 	List 
 		name: Harsha
 		hobbies: ["Reaading", "Coding", "Driving"]

 		 			(OR)

 		name: Harsha
 		hobbies: 
 			- Driving 
 			- Reading 
 			- Coding  					


apiVersion: v1
kind: Pod
metadata:
    name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
         - containerPort: 8080
       - containerPort: 50000
   

	apiVersion: v1
		- This is the version of api used to create a k8s object.
		- The fields are case-sensitive and YAML use camelcase.
		- The type of api are alpha, beta and stable.
		
	kind: Pod
		- here we specify which object we need to create. 
		- Always object name first letter is capital.
		
	metadata:
	    - This field is used to provide information on the object 
		  which we are creating.
		- Information such as name, labels and annotations. 	
	
	spec:
		- This is used to do the actual configuration of the 
		  object.

		 ports: 
		    - containerPort: 80	


To create / apply a configuration 
	kubectl apply -f <file>.yml	
	
To list objects 
	kubectl get <object_type>
		ex: List pods - kubectl get pods 
		    List deployment - kubectl get deployments
			
To delete objects 
	kubectl delete <object_type>

Deployment controller / Deployment / Deployment k8s
	- Deployment is used to create replicas of similar kind of pods and It makes sure that at a given point 
	  of time that number of replicas of pods is always running by using ReplicaSet controller.
	- If we update the configuration of deployment, it will automatically updates in all the pod replicas.
	- Rollout and Rollback of pod update is possible. We can use different deployment strategy for update,
	  by default it uses RollingUpdate. 
		Other strategies: canary, Recreate, Ramped and Blue-Green 
	- we can pause the deployment whenever we need.
	- Deployment internally got its own autoscaler which is of type horizontal smaller (hap).
	 
	  RollingUpdate	
		MaxSurge 
		  - Specifies the maximum number of pods the Deployment is allowed to create at one time. 
		  - You can specify this as a whole number (e.g. 5), or as a percentage of the total required number of pods 		
		         (e.g. 10%, always rounded up to the next whole number). 
		  - If you do not set MaxSurge, the implicit, default value is 25%.
		
		MaxUnavailable 
		  - specifies the maximum number of pods that are allowed to be unavailable during the rollout. 
		  - Like MaxSurge, you can define it as an absolute number or a percentage. 
	
	To scale up and scale down 
		1. We can update the replicas count in spec / configuration / yaml file.
		2. We can use kubectl cli 
			kubectl scale deployment.v1.apps/nginx-deployment --replicas=10

	To autoscale 
		1. kubectl autoscale deployment.v1.apps/nginx-deployment --min=5 --max=10 --cpu-percent=80

	deployment = pod + ReplicaSet + autoscalling + RollingUpdate + scale 

Labels, selector and annotations
	Labels:
		- K8S labels are provided as metadata key value to identify the object.
		- We can provide labels to any object in K8S
		- Labels are used to identify by selectors
		- We can have same label on multiple objects and 	

		To list labels of any object 
			kubectl get <object_type> <object_name> --show-labels	

	Selectors:
		- Selectors are used to select, filter and identify the labeled objects.

		Types of selectors 
			equality-based 
				- In this selector we can use only one operator which is equal_to (=, ==) or (!=) not_equal
				- It looks for exact match for the label  

				app = nginx  or app: nginx
				app != nginx

			set-based 
				- This type of selector allows to filter objects based on multiple set of values to a key.
				- operators that are supported are in , notin and exists

				app in (nginx, nginx1)
				app exists (nginx, nginx1)
				app notin (nginx, nginx1)

ReplicaSet vs Replication controller
	- Both ensures that at a given point of time the specified number of replicas are always running.
	- Replication controller is very old controller now it is replaced by ReplicaSet.
	- The only difference between them is Replication controller supports only equality-based selector but 
	  ReplicaSet support both set-based and equality based selector.

DaemonSet 
	- DaemonSet creates exactly one pod on each and every worker node in the cluster and ensures that all that are 
	  always running.
    - If a new worker node is added or deleted, DaemonSet will also add or delete the pod from the 
	  respective worker node.

Service (svc) (Basic network configurations in k8s)
	- Service is an REST api objects with which we can define policies to access set of pods.
	- Service are cluster level object.
	- By default, services are loadbalancers.
	- K8S Preffered port range for services is between 30000 - 50000.  
	
	ClusterIP
		- This is the default type of service in k8S.
		- using ClusterIP we can expose the IPs of pods to another set of pods with in the cluster.

		To check 
			1. Create a custom images and push to your Docker registry
				docker build -t <username>/<repo_name>:<tag> .
				docker login
				docker push 
			2. kubectl apply -f clusterIP.yml

			3. Login to any one pod
					kubectl exec -it <pod_name> /bin/bash

			4. Try to access the service - ClusterIP using <ClusterIP_ip_address>:<service_port>		 	
				curl </ClusterIP_ip_address>:<service_port>
				ex: (for i in {1..20}; do curl 10.101.209.36:30002; echo; done)

	NodePort
		- This service is most primitive way to get the external traffic directed to our applications 
		  running inside the cluster in pods.
		- Automatically a ClusterIP will also be created internally.

		NodePort = ClusterIP + a port mapping to the all the nodes ips. 		

		- If we wont specify any port while creating nodeport, k8s will Automatically asigns a random port 
		  between 30000 - 32767

namespaces (ns)
	- k8s namespaces is a way of applying abstraction / isolation to support multiple 
	  virtual clusters of k8s objects with in the same physical cluster.
	- Each and every object in k8s must be in a namespace.
	- If we wont specify namespace, objects will be created in default namespace of k8s.
    - namespaces are cluster level.
	- Namespace are only hidden from each other but not fully isolated because one 
	  service in a namespace can talk to another service in another namespace using 
	  fullname (service/<service_name>) followed by namespace name
	
	usage: we can apply environment based logical separation on cluster. 
		
	Type of deafault NS
	1. default
	   - This NS is used for all the objects which are not belongs to any other namespace.
	   - If we wont specify any namespace while creating an object in k8s then 
         that object will be created in deafult namespace.
			
	2. kube-system 
	   - This namespace is always used for objects created by the k8s system.
	   
	3. kube-public 
	   - The objects in this namespace are available or accessable to all.
       - All the objects in this namespace are made public.

	4. kube-node-lease 
	   - This namespace holds lease objects assosiated with each node.
	   - Node lease allows the kubelet to send heartbeats so that the control palne can 
		 detect node failure.

	To list namespaces 
		kubectl get namespaces 
		kubectl get ns	

	To list object in a namespace 
		kubectl get -n <namespace_name> <object_type>
	
	To list objects in all namespaces
		kubectl get --all-namespaces <object_type>
		kubectl get -A <object_type>

	To create a namespace 
		kubectl create ns <namespace_name>
		
	To create a object in a namespace 
		1. In metadata:
			namespace: <namespace_name>

		2. While apply 	
			kubectl apply -f <spec_file>.yml -n <namespace_name> 

		Note: If we provide namespace in both spec file and while apply, 
		      apply command check and compares the namespace in spec file if they are not same k8s won't 
		      allow us to create the object.	

Statefull Applications 
	- User session data is saved at the server side.
	- if server goes down, it is difficult to transfer the session data to other server. 
	- This type of application will not work, if we want to implement autoscaling.
	
Stateless Applications
	- user session-data is never saved at the server side.
	- using a common authentication gateway / client token method to validate the users 
	  once for multiple microservices.	
		
Monolothic and Microservice architecture 

	Monolothic architecture
		- A monolothic application has a single code base with multiple modules in it.
		- It is a single build for entire application.
		- To make minor changes to application, we need to re-build and re-deploy the 
		  complete application.
		- scaling is very challenging.
			
	Microservice architecture 
		- A microservice application is composed of small (micro) services. 
		- Each service will have a different code base.
		- Application are divided into as small as possible sub applications called services
		  which are independent to each other which are called loosely coupled.	
		- Each service can be managed separately and it is deployable separately.
		- Services need not to share same technology stack or frameworks.	

https://medium.com/@maneesa/what-happens-when-you-type-an-url-in-the-browser-and-press-enter-bb0aa2449c1a

https://medium.com/tech-tajawal/microservice-authentication-and-authorization-solutions-e0e5e74b248a

StatefullSet 
	StatefullSet = Deployment + sticky identity for each and every pod 

DNS syntax 
	Local 
		<object_name>.<namespace_name>.<object_type>.cluster.local
	
	From outside 
		<object_name>.<namespace_name>.<object_type>.<cluster_url>

Headless service 
	- If we don't need the default loadbalancing capability of services nor the single IP to service we use StatefullSet 
	- using Headless service we can get all the target pod ips, if we do nslookup.
	- It is created by sepcifying 'none' for ClusterIP
	- Headless service is usually used with StatefullSet controller.  


	- Headless service returns all the ips of the pods it is selecting.
	- headless service is created by specifying none for clusterIP 
	- headless service is usually used with statefulsets.
	
	Demo: 1. Create a headless service with statefulsets
	      2. Login to any one of pod - kubectl exec -it <pod_name> <command>
	      3. apt update && apt install dnsutils 
	      4. nslookup <service_name>

Pod lifecycle 
	1. pending 
		- This is the state of pod when pod will be waiting for k8s cluster to accept it.
		- pod will be downloading the image form registry.
		- pod will be in pending state if scheduler still trying to assign to a node.

	2. Running 
		- The pod got a node assigned and all the containers inside the pod is running.
		- At least one container is running and other in starting state (no container should be in exited)
		
	3. Failed 
		- All the container in pod should not be running and at least one container should be in terminated state 
		  in failure.
	
	4. Succeeded 
		- All the containers in pod have been terminated successfully / gracefully 
	
	5. Unknown 
		- For some other reason the API server can not get the pod state the it will put pod in Unknown state 
		- When k8s can't communicate with the worker node the it will put all the pods of that worker node to unknown.

	6. Terminating
		- when pod is being deleted 
	
	Container status 
		Running 
			- When container is running the process without error 
		
		Terminated 
			- Process inside the container has completed the execution successfully or it may be failed 
			  due to error.
		
		Waiting
			- If a container is not running or neither in terminated state.

Service Discovery (microservice access)
	Questions 
		- How a microservice will communicate with other microservice
		- pod to pod communicate 

	kubectl cluster-info
		to get ip address of our k8s cluster and also CoreDNS address 

	1. Services 
		- we can use the fullname of service to Discovery a microservice (pod)		
			fullname - (service/<service_name>)

	2. DNS 
		- DNS server is added to the cluster by k8s in order to map the service request.
		- When ever we create a service k8s will Automatically create a DNS record for it.
					A - (target always ip address )  CNAME (another DNS) 	
		- Record type A is used in k8s service Discovery and this is created on objects with IP 
			(pods, services) 			

		syntax: 
				mail.google.com 
					.com (top level domain type)
					google (name of the main domain)
					mail (name of the subdomain)	

				K8S DNS 
					<object_name>.<namespace_name>.<object_type>.cluster.local

					ex: my-clusterip-ip-app.default.svc.cluster.local	

	3. K8S ENV 	
		- These are environment variables which k8s auto creates in each and every pod 
		  which is connected to a service 
		- KUBERNETES_SERVICE_PORT_HTTPS=443
		- KUBERNETES_SERVICE_PORT=443
		- KUBERNETES_PORT_443_TCP=tcp://10.96.0.1:443
		- KUBERNETES_PORT_443_TCP_PROTO=tcp
		- KUBERNETES_PORT_443_TCP_ADDR=10.96.0.1
		- KUBERNETES_SERVICE_HOST=10.96.0.1
		- KUBERNETES_PORT=tcp://10.96.0.1:443
		- KUBERNETES_PORT_443_TCP_PORT=443  

ConfigMaps and Secrets 
	- Cofigmaps are k8s objects that allows us to separate and attach configuration data from the image content of the pod.
	- We attach environment variables to the pod. 
	- The data is not encrypted by default in configmaps so better to use non-confidential data in configmaps.
	
	Create a configmap
		1. Create a file by name "app.properties"
			environment=test
			database_url="192.168.1.1"
			database_password="adjhfgjladhgalhg"
			
		2. Load the single config file 
			kubectl create configmap <configmap_name> --from-file configs/app.properties

		   Load the multiple config files 	
			kubectl create configmap <configmap_name> --from-file configs/
	
	Create a secret 
		- Data by default encrypted by base64 format and we use it for confidential data 

		1. Get values in base64 format 
			echo -n '<value>' | base64 

		2. Copy the base64 value got from above command and use it in secrets 

			apiVersion: v1
			kind: Secret
			metadata: 
    			    name: my-secret
			type: Opaque    
			data:
   				db_url: cG9zdGdyYXNlLmRlZmF1bHQuc3ZjLmNsdXN0ZXIubG9jYWw=
   				db_username: dGVzdF91c2Vy
   				db_password: cGFzc3dvcmQ= 
		
		3. Types of secrets 
			Opaque					arbitrary user-defined data
			kubernetes.io/service-account-token	ServiceAccount token
			kubernetes.io/dockercfg			serialized ~/.dockercfg file
			kubernetes.io/dockerconfigjson		serialized ~/.docker/config.json file
			kubernetes.io/basic-auth			credentials for basic authentication
			kubernetes.io/ssh-auth			credentials for SSH authentication
			kubernetes.io/tls			data for a TLS client or server
		
		4. Using secrets in pod spec

			env: 
       			   - name: DB_URL
         		     valueFrom: 
            		        secretKeyRef: 
               				name: my-secret
               				key: db_url

Persistent Volume (pv)
	- It is a storage space which we reserve as persistent volume.
	- This storage space can be claimed to any pod in the cluster. 
	- These are cluster level object and not bounded to namespace.
	
	we can control the access  (accessModes)
	 - ROX (ReadOnlyMany) 
		Volume can be claimed from multiple worker nodes in read-only mode 
	 - RWX (ReadWriteMany)
		Volume can be claimed from multiple worker nodes in read-write mode 
	 - RWO (ReadWriteOnce)
		- Volume can be claimed from only one worker node in read-write mode. 
		- k8s allow multiple pods to access the volume when the pods are running on the same node.
         - RWOP (ReadWriteOncePod)
                - The volume can be mounted as read-write by only a single Pod. 
		- Use ReadWriteOncePod access mode if you want to ensure that only one pod across whole cluster 
		  can read-write that PVC.

Persistent Volume Claim (pvc)
	- This is the amount of memory needed to claim in any pod based on the access modes.
	- After we create pic, k8s looks for a Persistent Volume which matches the claim same configuration.
	- If Persistent Volume is found with same configuration, it binds the claim to the pod as volume. 

Assignment: 
	- Dynamic volume provisioning 
	- Storage class 	

kubernetes container types (multi container pod patterns)
	In a pod we will always have only one main application container and all the other containers are to support and 
	extend the functionality of the application container.	

	init container 
		- init containers are the containers that will run completely before starting 
		  the main app container.
		- This provides a lifecycle at the startup and we can define things for 
		initialization purpose.
		- kubernetes has stopped support of probes in init containers.
		- These are pod level objects.
		- we can use this container to have some deply on the startup of the main container.
	
		These are some of the scenarios where you can use this pattern
		- You can use this pattern where your application or main containers need some
		  prerequisites such as installing some software, database setup, permissions on the file
		  system before starting.
		- You can use this pattern where you want to delay the start of the main containers.

	Demo steps (kubectl apply -f init_container.yml)
		1. login to pod 
				kubectl exec -it <pod_name> -- /bin/sh 
		2. apt update && apt install -y curl 
		3. curl localhost
			
		To check the log of particular container out of multiple in a pod 
			kubectl logs <pod_name> -c <container_name>


	Sidecar container 
	- These are the containers that will run along with the main app container.
	- we have a app container which is working fine but we want to extend the 
	  functionality without changing the existing code in main container for this 
      purpose we can use sidecar container.
    - we use this container to feed the log data to monitoring tools.	
	
	These are some of the scenarios where you can use this pattern
		- Whenever you want to extend the functionality of the existing single container pod without
		  touching the existing one.
		- Whenever you want to enhance the functionality of the existing single container pod
		  without touching the existing one.
		- You can use this pattern to synchronize the main container code with the git server pull.
		- You can use this pattern for sending log events to the external server.
		- You can use this pattern for network-related tasks.
	
Adaptor container 
	- In this patter we use a sidecar container to feed the log data to a monitoring tool.
	https://www.magalix.com/blog/kubernetes-patterns-the-ambassador-pattern
	Note: In linux, If we want to print a file which getting updated live - tail -f <file_name>




